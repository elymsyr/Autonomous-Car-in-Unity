{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Convolutional Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate \n",
    "from tensorflow.keras.layers import Input, Add, Conv2DTranspose\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy, MeanSquaredError, BinaryCrossentropy\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import callbacks\n",
    "\n",
    "from  matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load directories\n",
    "train_data_dir = \"/home/things/Documents/KITTI/RoadSegmantation/data_road/training/image_2/\"\n",
    "train_gt_dir = \"/home/things/Documents/KITTI/RoadSegmantation/data_road/training/gt_image_2/\"\n",
    "\n",
    "test_data_dir = \"/home/things/Documents/KITTI/RoadSegmantation/data_road/testing/image_2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Number of training examples\n",
    "TRAINSET_SIZE = int(len(os.listdir(train_data_dir)) * 0.9)\n",
    "print(f\"Number of Training Examples: {TRAINSET_SIZE}\")\n",
    "\n",
    "VALIDSET_SIZE = int(len(os.listdir(train_data_dir)) - TRAINSET_SIZE)\n",
    "print(f\"Number of Validation Examples: {VALIDSET_SIZE}\")\n",
    "\n",
    "TESTSET_SIZE = int(len(os.listdir(test_data_dir)))\n",
    "print(f\"Number of Testing Examples: {TESTSET_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize Constants\n",
    "IMG_SIZE = 128\n",
    "GRAY = True\n",
    "N_CHANNELS = 1 if GRAY else 3\n",
    "N_CLASSES = 1\n",
    "SEED = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to load image and return a dictionary\n",
    "def parse_image(img_path: str) -> dict:\n",
    "    image = tf.io.read_file(img_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.uint8)\n",
    "\n",
    "    # Three types of img paths: um, umm, uu\n",
    "    # gt image paths: um_road, umm_road, uu_road\n",
    "    mask_path = tf.strings.regex_replace(img_path, \"image_2\", \"gt_image_2\")\n",
    "    mask_path = tf.strings.regex_replace(mask_path, \"um_\", \"um_road_\")\n",
    "    mask_path = tf.strings.regex_replace(mask_path, \"umm_\", \"umm_road_\")\n",
    "    mask_path = tf.strings.regex_replace(mask_path, \"uu_\", \"uu_road_\")\n",
    "    \n",
    "    mask = tf.io.read_file(mask_path)\n",
    "    mask = tf.image.decode_png(mask, channels=3)\n",
    "    \n",
    "    non_road_label = np.array([255, 0, 0])\n",
    "    road_label = np.array([255, 0, 255])\n",
    "    other_road_label = np.array([0, 0, 0])\n",
    "    \n",
    "    # Convert to mask to binary mask\n",
    "    mask = tf.experimental.numpy.all(mask == road_label, axis = 2)\n",
    "    mask = tf.cast(mask, tf.uint8)\n",
    "    mask = tf.expand_dims(mask, axis=-1)\n",
    "\n",
    "    return {'image': image, 'segmentation_mask': mask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Generate dataset variables\n",
    "all_dataset = tf.data.Dataset.list_files(train_data_dir + \"*.png\", seed=SEED)\n",
    "all_dataset = all_dataset.map(parse_image)\n",
    "\n",
    "train_dataset = all_dataset.take(TRAINSET_SIZE + VALIDSET_SIZE)\n",
    "val_dataset = train_dataset.skip(TRAINSET_SIZE)\n",
    "train_dataset = train_dataset.take(TRAINSET_SIZE)\n",
    "test_dataset = all_dataset.skip(TRAINSET_SIZE + VALIDSET_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Tensorflow function to rescale images to [0, 1]\n",
    "@tf.function\n",
    "def normalize(input_image: tf.Tensor, input_mask: tf.Tensor) -> tuple:\n",
    "    global GRAY\n",
    "    if GRAY: input_image = tf.image.rgb_to_grayscale(input_image)\n",
    "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
    "    return input_image, input_mask\n",
    "\n",
    "# Tensorflow function to apply preprocessing transformations\n",
    "@tf.function\n",
    "def load_image_train(datapoint: dict) -> tuple:\n",
    "    input_image = tf.image.resize(datapoint['image'], (IMG_SIZE, IMG_SIZE))\n",
    "    input_mask = tf.image.resize(datapoint['segmentation_mask'], (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        input_image = tf.image.flip_left_right(input_image)\n",
    "        input_mask = tf.image.flip_left_right(input_mask)\n",
    "\n",
    "    input_image, input_mask = normalize(input_image, input_mask)\n",
    "\n",
    "    return input_image, input_mask\n",
    "\n",
    "# Tensorflow function to preprocess validation images\n",
    "@tf.function\n",
    "def load_image_test(datapoint: dict) -> tuple:\n",
    "    input_image = tf.image.resize(datapoint['image'], (IMG_SIZE, IMG_SIZE))\n",
    "    input_mask = tf.image.resize(datapoint['segmentation_mask'], (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    input_image, input_mask = normalize(input_image, input_mask)\n",
    "\n",
    "    return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 1000\n",
    "\n",
    "dataset = {\"train\": train_dataset, \"val\": val_dataset, \"test\": test_dataset}\n",
    "\n",
    "# -- Train Dataset --#\n",
    "dataset['train'] = dataset['train'].map(load_image_train, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "dataset['train'] = dataset['train'].shuffle(buffer_size=BUFFER_SIZE, seed=SEED)\n",
    "dataset['train'] = dataset['train'].repeat()\n",
    "dataset['train'] = dataset['train'].batch(BATCH_SIZE)\n",
    "dataset['train'] = dataset['train'].prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "#-- Validation Dataset --#\n",
    "dataset['val'] = dataset['val'].map(load_image_test)\n",
    "dataset['val'] = dataset['val'].repeat()\n",
    "dataset['val'] = dataset['val'].batch(BATCH_SIZE)\n",
    "dataset['val'] = dataset['val'].prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "#-- Testing Dataset --#\n",
    "dataset['test'] = dataset['test'].map(load_image_test)\n",
    "dataset['test'] = dataset['test'].batch(BATCH_SIZE)\n",
    "dataset['test'] = dataset['test'].prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "print(dataset['train'])\n",
    "print(dataset['val'])\n",
    "print(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to view the images from the directory\n",
    "def display_sample(display_list):\n",
    "    plt.figure(figsize=(18, 18))\n",
    "\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "for image, mask in dataset[\"train\"].take(1):\n",
    "    sample_image, sample_mask = image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "display_sample([sample_image[5], sample_mask[5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Get VGG-16 network as backbone\n",
    "vgg16_model = VGG16()\n",
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define input shape\n",
    "input_shape = (IMG_SIZE, IMG_SIZE, N_CHANNELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Generate a new model using the VGG network\n",
    "# Input\n",
    "inputs = Input(input_shape)\n",
    "\n",
    "# VGG network\n",
    "vgg16_model = VGG16(include_top = False, weights = 'imagenet', input_tensor = inputs)\n",
    "\n",
    "# Encoder Layers\n",
    "c1 = vgg16_model.get_layer(\"block3_pool\").output         \n",
    "c2 = vgg16_model.get_layer(\"block4_pool\").output         \n",
    "c3 = vgg16_model.get_layer(\"block5_pool\").output         \n",
    "\n",
    "# Decoder\n",
    "u1 = UpSampling2D((2, 2), interpolation = 'bilinear')(c3)\n",
    "d1 = Concatenate()([u1, c2])\n",
    "\n",
    "u2 = UpSampling2D((2, 2), interpolation = 'bilinear')(d1)\n",
    "d2 = Concatenate()([u2, c1])\n",
    "\n",
    "# Output\n",
    "u3 = UpSampling2D((8, 8), interpolation = 'bilinear')(d2)\n",
    "outputs = Conv2D(N_CLASSES, 1, activation = 'sigmoid')(u3)\n",
    "\n",
    "model = Model(inputs, outputs, name = \"VGG_FCN8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "m_iou = tf.keras.metrics.MeanIoU(2)\n",
    "model.compile(optimizer=Adam(),\n",
    "              loss=BinaryCrossentropy(),\n",
    "              metrics=[m_iou])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to create a mask out of network prediction\n",
    "def create_mask(pred_mask: tf.Tensor) -> tf.Tensor:\n",
    "    # Round to closest\n",
    "    pred_mask = tf.math.round(pred_mask)\n",
    "    \n",
    "    # [IMG_SIZE, IMG_SIZE] -> [IMG_SIZE, IMG_SIZE, 1]\n",
    "    pred_mask = tf.expand_dims(pred_mask, axis=-1)\n",
    "    return pred_mask\n",
    "\n",
    "# Function to show predictions\n",
    "def show_predictions(dataset=None, num=1):\n",
    "    if dataset:\n",
    "        # Predict and show image from input dataset\n",
    "        for image, mask in dataset.take(num):\n",
    "            pred_mask = model.predict(image)\n",
    "            display_sample([image[0], true_mask, create_mask(pred_mask)])\n",
    "    else:\n",
    "        # Predict and show the sample image\n",
    "        inference = model.predict(sample_image)\n",
    "        display_sample([sample_image[0], sample_mask[0],\n",
    "                        inference[0]])\n",
    "        \n",
    "for image, mask in dataset['train'].take(1):\n",
    "    sample_image, sample_mask = image, mask\n",
    "\n",
    "show_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Callbacks and Logs\n",
    "class DisplayCallback(callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        clear_output(wait=True)\n",
    "        show_predictions()\n",
    "        print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))\n",
    "\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "callbacks = [\n",
    "    DisplayCallback(),\n",
    "    callbacks.TensorBoard(logdir, histogram_freq = -1),\n",
    "    callbacks.EarlyStopping(patience = 10, verbose = 1),\n",
    "    callbacks.ModelCheckpoint('best_model.h5', verbose = 1, save_best_only = True)\n",
    "]\n",
    "        \n",
    "# Set Variables\n",
    "EPOCHS = 200\n",
    "STEPS_PER_EPOCH = TRAINSET_SIZE // BATCH_SIZE\n",
    "VALIDATION_STEPS = VALIDSET_SIZE // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_history = model.fit(dataset['train'], epochs=EPOCHS,\n",
    "                          steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                          validation_data = dataset[\"val\"],\n",
    "                          validation_steps=VALIDATION_STEPS,\n",
    "                          callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing (Test Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to calculate mask over image\n",
    "def weighted_img(img, initial_img, α=1., β=0.5, γ=0.):\n",
    "    return cv2.addWeighted(initial_img, α, img, β, γ)\n",
    "\n",
    "# Function to process an individual image and it's mask\n",
    "def process_image_mask(image, mask):\n",
    "    # Round to closest\n",
    "    mask = tf.math.round(mask)\n",
    "    \n",
    "    # Convert to mask image\n",
    "    zero_image = np.zeros_like(mask)\n",
    "    mask = np.dstack((mask, zero_image, zero_image))\n",
    "    mask = np.asarray(mask, np.float32)\n",
    "    \n",
    "    # Convert to image image\n",
    "    image = np.asarray(image, np.float32)\n",
    "    \n",
    "    # Get the final image\n",
    "    final_image = weighted_img(mask, image)\n",
    "\n",
    "    return final_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to save predictions\n",
    "def save_predictions(dataset):\n",
    "    # Predict and save image the from input dataset\n",
    "    index = 0\n",
    "    for batch_image, batch_mask in dataset:\n",
    "        for image, mask in zip(batch_image, batch_mask):\n",
    "            print(f\"Processing image : {index}\")\n",
    "            pred_mask = model.predict(tf.expand_dims(image, axis = 0))\n",
    "            save_sample([image, process_image_mask(image, pred_mask[0])], index)\n",
    "            index += 1\n",
    "\n",
    "# Function to save the images as a plot\n",
    "def save_sample(display_list, index):\n",
    "    plt.figure(figsize=(18, 18))\n",
    "\n",
    "    title = ['Input Image', 'Predicted Mask']\n",
    "\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "        \n",
    "    plt.savefig(f\"outputs/{index}.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "os.mkdir(\"outputs\")\n",
    "save_predictions(dataset['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing (Videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to view video\n",
    "def play(filename):\n",
    "    html = ''\n",
    "    video = open(filename,'rb').read()\n",
    "    src = 'data:video/mp4;base64,' + b64encode(video).decode()\n",
    "    html += '<video width=1000 controls autoplay loop><source src=\"%s\" type=\"video/mp4\"></video>' % src \n",
    "    return HTML(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to process an individual image\n",
    "def process_image(image):\n",
    "    # Preprocess image\n",
    "    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    # Get the binary mask\n",
    "    pred_mask = model.predict(np.expand_dims(image, axis = 0))\n",
    "    mask = np.round_(pred_mask[0])\n",
    "    \n",
    "    # Convert to mask image\n",
    "    zero_image = np.zeros_like(mask)\n",
    "    mask = np.dstack((mask, zero_image, zero_image)) * 255\n",
    "    mask = np.asarray(mask, np.uint8)\n",
    "    \n",
    "    # Get the final image\n",
    "    final_image = weighted_img(mask, image)\n",
    "    final_image = cv2.resize(final_image, (1280, 720))\n",
    "\n",
    "    return final_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Make a new directory\n",
    "os.mkdir(\"videos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Creating a VideoCapture object to read the video\n",
    "project_video = \"project_video.mp4\"\n",
    "original_video = cv2.VideoCapture(test_data_dir + project_video)\n",
    "frame_width = int(original_video.get(3))\n",
    "frame_height = int(original_video.get(4))\n",
    " \n",
    "# Define the codec and create VideoWriter object.The output is stored in 'outpy.avi' file.\n",
    "fourcc = cv2.VideoWriter_fourcc('m','p','4','v')\n",
    "fps = 60\n",
    "output = cv2.VideoWriter(\"videos/\" + project_video, fourcc, fps, (frame_width,frame_height))\n",
    "\n",
    "# Process Video\n",
    "while(original_video.isOpened()):\n",
    "    ret, frame = original_video.read()\n",
    "\n",
    "    if ret == True:\n",
    "        # Write the frame into the file 'output.avi'\n",
    "        output.write(process_image(frame))\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# When everything done, release the video capture and video write objects\n",
    "original_video.release()\n",
    "output.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "play(\"videos/\" + project_video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Creating a VideoCapture object to read the video\n",
    "project_video = \"challenge.mp4\"\n",
    "original_video = cv2.VideoCapture(test_data_dir + project_video)\n",
    "frame_width = int(original_video.get(3))\n",
    "frame_height = int(original_video.get(4))\n",
    " \n",
    "# Define the codec and create VideoWriter object.The output is stored in 'outpy.avi' file.\n",
    "fourcc = cv2.VideoWriter_fourcc('m','p','4','v')\n",
    "fps = 60\n",
    "output = cv2.VideoWriter(\"videos/\" + project_video, fourcc, fps, (frame_width,frame_height))\n",
    "\n",
    "# Process Video\n",
    "while(original_video.isOpened()):\n",
    "    ret, frame = original_video.read()\n",
    "\n",
    "    if ret == True:\n",
    "        # Write the frame into the file 'output.avi'\n",
    "        output.write(process_image(frame))\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# When everything done, release the video capture and video write objects\n",
    "original_video.release()\n",
    "output.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "play(\"videos/\" + project_video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge Video 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Creating a VideoCapture object to read the video\n",
    "project_video = \"challenge_video.mp4\"\n",
    "original_video = cv2.VideoCapture(test_data_dir + project_video)\n",
    "frame_width = int(original_video.get(3))\n",
    "frame_height = int(original_video.get(4))\n",
    " \n",
    "# Define the codec and create VideoWriter object.The output is stored in 'outpy.avi' file.\n",
    "fourcc = cv2.VideoWriter_fourcc('m','p','4','v')\n",
    "fps = 60\n",
    "output = cv2.VideoWriter(\"videos/\" + project_video, fourcc, fps, (frame_width,frame_height))\n",
    "\n",
    "# Process Video\n",
    "while(original_video.isOpened()):\n",
    "    ret, frame = original_video.read()\n",
    "\n",
    "    if ret == True:\n",
    "        # Write the frame into the file 'output.avi'\n",
    "        output.write(process_image(frame))\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# When everything done, release the video capture and video write objects\n",
    "original_video.release()\n",
    "output.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "play(\"videos/\" + project_video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Harder Challenge Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Creating a VideoCapture object to read the video\n",
    "project_video = \"harder_challenge_video.mp4\"\n",
    "original_video = cv2.VideoCapture(test_data_dir + project_video)\n",
    "frame_width = int(original_video.get(3))\n",
    "frame_height = int(original_video.get(4))\n",
    " \n",
    "# Define the codec and create VideoWriter object.The output is stored in 'outpy.avi' file.\n",
    "fourcc = cv2.VideoWriter_fourcc('m','p','4','v')\n",
    "fps = 60\n",
    "output = cv2.VideoWriter(\"videos/\" + project_video, fourcc, fps, (frame_width,frame_height))\n",
    "\n",
    "# Process Video\n",
    "while(original_video.isOpened()):\n",
    "    ret, frame = original_video.read()\n",
    "\n",
    "    if ret == True:\n",
    "        # Write the frame into the file 'output.avi'\n",
    "        output.write(process_image(frame))\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# When everything done, release the video capture and video write objects\n",
    "original_video.release()\n",
    "output.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "play(\"videos/\" + project_video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [Kitti Dataset Processing](http://ronny.rest/blog/post_2017_09_06_kitti_road_data/)\n",
    "- [Image Segmentation on Keras](https://yann-leguilly.gitlab.io/post/2019-12-14-tensorflow-tfdata-segmentation/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1668350,
     "sourceId": 2736560,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30140,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "tracker3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
